{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 1. Data exploration\n",
    "\n",
    "Exploração dos dados baseado em:\n",
    "\n",
    "- __1500__ observações\n",
    "- __7__ características \n",
    "- __3__ usuários distintos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Get started"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>rate_blink_left</th>\n",
       "      <th>rate_blink_right</th>\n",
       "      <th>rate_smile_or_not</th>\n",
       "      <th>blink_left</th>\n",
       "      <th>blink_right</th>\n",
       "      <th>smile_or_not</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>2</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>2</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>2</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>2</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>2</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>2</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>2</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>2</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>2</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>2</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>2</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>2</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>2</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>2</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>2</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>2</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>2</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>2</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>2</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>2</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>2</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>2</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>2</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>2</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>2</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>2</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>2</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>2</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>2</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>2</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    user  rate_blink_left  rate_blink_right  rate_smile_or_not  blink_left  \\\n",
       "0      2             0.67              0.67               0.00           0   \n",
       "1      2             0.76              0.89               0.00           0   \n",
       "2      2             0.85              0.60               0.00           0   \n",
       "3      2             0.72              0.37               0.00           0   \n",
       "4      2             0.35              0.10               0.00           1   \n",
       "5      2             0.74              0.63               0.00           0   \n",
       "6      2             0.58              0.73               0.00           0   \n",
       "7      2             0.93              0.99               0.61           0   \n",
       "8      2             0.73              0.84               0.00           0   \n",
       "9      2             0.81              0.87               0.00           0   \n",
       "10     2             0.52              0.44               0.00           0   \n",
       "11     2             0.65              0.71               0.00           0   \n",
       "12     2             0.75              0.72               0.00           0   \n",
       "13     2             0.57              0.60               0.00           0   \n",
       "14     2             0.80              0.95               0.96           0   \n",
       "15     2             0.56              0.65               0.96           0   \n",
       "16     2             0.87              0.74               0.00           0   \n",
       "17     2             0.77              0.85               0.00           0   \n",
       "18     2             0.56              0.55               0.00           0   \n",
       "19     2             0.72              0.37               0.00           0   \n",
       "20     2             0.76              0.72               0.00           0   \n",
       "21     2             0.31              0.73               0.00           1   \n",
       "22     2             0.72              0.81               0.00           0   \n",
       "23     2             0.68              0.56               0.00           0   \n",
       "24     2             0.60              0.61               0.00           0   \n",
       "25     2             0.80              0.75               0.93           0   \n",
       "26     2             0.65              0.55               0.00           0   \n",
       "27     2             0.64              0.73               0.00           0   \n",
       "28     2             0.54              0.12               0.00           0   \n",
       "29     2             0.53              0.45               0.00           0   \n",
       "..   ...              ...               ...                ...         ...   \n",
       "70     2             0.79              0.56               0.00           0   \n",
       "71     2             0.60              0.45               0.00           0   \n",
       "72     2             0.40              0.53               0.00           1   \n",
       "73     2             0.39              0.56               0.00           1   \n",
       "74     2             0.36              0.54               0.00           1   \n",
       "75     2             0.66              0.57               0.00           0   \n",
       "76     2             0.74              0.98               0.00           0   \n",
       "77     2             0.77              0.58               0.00           0   \n",
       "78     2             0.31              0.58               0.00           1   \n",
       "79     2             0.99              0.58               0.00           0   \n",
       "80     2             0.90              0.97               0.37           0   \n",
       "81     2             0.33              0.61               0.00           1   \n",
       "82     2             0.51              0.71               0.00           0   \n",
       "83     2             0.43              0.33               0.00           1   \n",
       "84     2             0.61              0.67               0.00           0   \n",
       "85     2             0.64              0.68               0.00           0   \n",
       "86     2             0.58              0.51               0.00           0   \n",
       "87     2             0.82              0.63               0.95           0   \n",
       "88     2             0.52              0.91               0.00           0   \n",
       "89     2             0.72              0.42               0.00           0   \n",
       "90     2             0.80              0.52               0.00           0   \n",
       "91     2             0.39              0.72               0.00           1   \n",
       "92     2             0.68              0.78               0.00           0   \n",
       "93     2             0.58              0.69               0.00           0   \n",
       "94     2             0.53              0.69               0.00           0   \n",
       "95     2             0.64              0.86               0.00           0   \n",
       "96     2             0.89              0.85               0.00           0   \n",
       "97     2             0.02              0.30               0.00           1   \n",
       "98     2             0.81              0.65               0.00           0   \n",
       "99     2             0.57              0.65               0.00           0   \n",
       "\n",
       "    blink_right  smile_or_not  \n",
       "0             0             0  \n",
       "1             0             0  \n",
       "2             0             0  \n",
       "3             1             0  \n",
       "4             1             0  \n",
       "5             0             0  \n",
       "6             0             0  \n",
       "7             0             1  \n",
       "8             0             0  \n",
       "9             0             0  \n",
       "10            1             0  \n",
       "11            0             0  \n",
       "12            0             0  \n",
       "13            0             0  \n",
       "14            0             1  \n",
       "15            0             1  \n",
       "16            0             0  \n",
       "17            0             0  \n",
       "18            0             0  \n",
       "19            1             0  \n",
       "20            0             0  \n",
       "21            0             0  \n",
       "22            0             0  \n",
       "23            0             0  \n",
       "24            0             0  \n",
       "25            0             1  \n",
       "26            0             0  \n",
       "27            0             0  \n",
       "28            1             0  \n",
       "29            1             0  \n",
       "..          ...           ...  \n",
       "70            0             0  \n",
       "71            1             0  \n",
       "72            0             0  \n",
       "73            0             0  \n",
       "74            0             0  \n",
       "75            0             0  \n",
       "76            0             0  \n",
       "77            0             0  \n",
       "78            0             0  \n",
       "79            0             0  \n",
       "80            0             1  \n",
       "81            0             0  \n",
       "82            0             0  \n",
       "83            1             0  \n",
       "84            0             0  \n",
       "85            0             0  \n",
       "86            0             0  \n",
       "87            0             1  \n",
       "88            0             0  \n",
       "89            1             0  \n",
       "90            0             0  \n",
       "91            0             0  \n",
       "92            0             0  \n",
       "93            0             0  \n",
       "94            0             0  \n",
       "95            0             0  \n",
       "96            0             0  \n",
       "97            1             0  \n",
       "98            0             0  \n",
       "99            0             0  \n",
       "\n",
       "[100 rows x 7 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from data import get_full_data, get_who_is\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn import linear_model\n",
    "from predicting_who_is import accuracy_score, performance_metric\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from IPython.display import display # Allows the use of display() for DataFrames\n",
    "\n",
    "# Import supplementary visualizations code visuals.py\n",
    "import visuals as vs\n",
    "\n",
    "X, Y, df = get_full_data()\n",
    "\n",
    "#df = df.sample(frac=1)\n",
    "\n",
    "#X = df[df['user'] == 2][['rate_blink_left', 'rate_blink_right', 'rate_smile_or_not', 'blink_left', 'blink_right', 'smile_or_not']]\n",
    "#Y = df[df['user'] == 2]['user']\n",
    "\n",
    "#X = df[['blink_left', 'blink_right', 'smile_or_not']]\n",
    "# Y = df['user']\n",
    "\n",
    "Xdummies_df = pd.get_dummies(X)\n",
    "Ydummies_df = Y\n",
    "\n",
    "X = Xdummies_df.values\n",
    "Y = Ydummies_df.values\n",
    "\n",
    "# Print the first few entries of the RMS Titanic data\n",
    "display(df.head(100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Create a function to analysing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Investigar \n",
    "# http://www.dummies.com/programming/big-data/data-science/how-to-visualize-the-classifier-in-an-svm-supervised-learning-model/\n",
    "# http://scikit-learn.org/stable/auto_examples/svm/plot_iris.html#sphx-glr-auto-examples-svm-plot-iris-py\n",
    "# http://scikit-learn.org/stable/auto_examples/plot_multilabel.html#sphx-glr-auto-examples-plot-multilabel-py\n",
    "#http://scikit-learn.org/stable/auto_examples/classification/plot_classifier_comparison.html#sphx-glr-auto-examples-classification-plot-classifier-comparison-py\n",
    "def display_points(X, Y):\n",
    "    from sklearn.decomposition import PCA\n",
    "    from sklearn import svm\n",
    "    from sklearn.tree import DecisionTreeClassifier\n",
    "    from sklearn.cross_validation import train_test_split\n",
    "    import pylab as pl\n",
    "    import numpy as np\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.20, random_state=0)\n",
    "    pca = PCA(n_components=2).fit(X_train)\n",
    "    pca_2d = pca.transform(X_train)\n",
    "    svmClassifier_2d = svm.LinearSVC(random_state=0).fit(pca_2d, y_train)\n",
    "    #clf = DecisionTreeClassifier().fit(pca_2d, y_train)\n",
    "    for i in range(0, pca_2d.shape[0]):\n",
    "        if y_train[i] == 1:\n",
    "            c1 = pl.scatter(pca_2d[i,0],pca_2d[i,1], c='r', s=50,marker='+')\n",
    "        elif y_train[i] == 2:\n",
    "            c2 = pl.scatter(pca_2d[i,0],pca_2d[i,1], c='g', s=50,marker='o')\n",
    "        elif y_train[i] == 3:\n",
    "            c3 = pl.scatter(pca_2d[i,0],pca_2d[i,1], c='b', s=50,marker='*')\n",
    "\n",
    "    pl.legend([c1, c2], ['Thiago', 'Alessandro'])\n",
    "    \n",
    "    x_min, x_max = pca_2d[:, 0].min() - 1, pca_2d[:,0].max() + 1\n",
    "    y_min, y_max = pca_2d[:, 1].min() - 1, pca_2d[:, 1].max() + 1\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, .01), np.arange(y_min, y_max, .01))\n",
    "    Z = svmClassifier_2d.predict(np.c_[xx.ravel(),  yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    pl.contour(xx, yy, Z, alpha=0.8)\n",
    "    \n",
    "    plt.xlim(xx.min(), xx.max())\n",
    "    plt.ylim(yy.min(), yy.max())\n",
    "    plt.xticks(())\n",
    "    plt.yticks(())\n",
    "    \n",
    "    pl.show()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "###  Feature Observation\n",
    "\n",
    "We are see the 6 features in dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWQAAADuCAYAAAAOR30qAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nVkICWQghrIQEshBCWAkJZCGEsBL/H+8Y4FuC7d2xAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f591c553090>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_points(X, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 2. Developing a model\n",
    "\n",
    "In this second section of the project, you will develop the tools and techniques necessary for a model to make a prediction. Being able to make accurate evaluations of each model's performance through the use of these tools and techniques helps to greatly reinforce the confidence in your predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Shuffle and split data\n",
    "\n",
    "For the code cell below, you will need to implement the following:\n",
    "\n",
    "- Use train_test_split from sklearn.cross_validation to shuffle and split the features and prices data into training and testing sets.\n",
    "    - Split the data into 80% training and 20% testing.\n",
    "    - Set the random_state for train_test_split to a value of your choice. This ensures results are consistent.\n",
    "- Assign the train and testing splits to X_train, X_test, y_train, and y_test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and testing split was successful.\n"
     ]
    }
   ],
   "source": [
    "# Import 'train_test_split'\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "# Shuffle and split the data into training and testing subsets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, train_size = 0.8, random_state = 0)\n",
    "\n",
    "# Success\n",
    "print \"Training and testing split was successful.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Performance Metric\n",
    "\n",
    "It is difficult to measure the quality of a given model without quantifying its performance over training and testing. This is typically done using some type of performance metric, whether it is through calculating some type of error, the goodness of fit, or some other useful measurement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Algorithm OneVsRestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def model_1(resultados):\n",
    "    from sklearn.multiclass import OneVsRestClassifier\n",
    "    from sklearn.svm import LinearSVC\n",
    "    modelo = OneVsRestClassifier(LinearSVC(random_state = 0))\n",
    "    resultado = accuracy_score(\"OneVsRest\", modelo, X_train, y_train)\n",
    "\n",
    "    resultados[resultado] = modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Algorithm OneVsOne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def model_2(resultados):\n",
    "    from sklearn.multiclass import OneVsOneClassifier\n",
    "    from sklearn.svm import LinearSVC\n",
    "    modelo = OneVsOneClassifier(LinearSVC(random_state = 0))\n",
    "    resultado = accuracy_score(\"OneVsOne\", modelo, X_train, y_train)\n",
    "\n",
    "    resultados[resultado] = modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Algorithm MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def model_3(resultados):\n",
    "    from sklearn.naive_bayes import MultinomialNB\n",
    "    modelo = MultinomialNB()\n",
    "    resultado = accuracy_score(\"MultinomialNB\", modelo, X_train, y_train)\n",
    "\n",
    "    resultados[resultado] = modelo "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Algorithm AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def model_4(resultados):\n",
    "    from sklearn.ensemble import AdaBoostClassifier\n",
    "    modelo = AdaBoostClassifier()\n",
    "    resultado = accuracy_score(\"AdaBoostClassifier\", modelo, X_train, y_train)\n",
    "\n",
    "    resultados[resultado] = modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Algorithm LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def model_5(resultados):\n",
    "    from sklearn.svm import LinearSVC\n",
    "    modelo = LinearSVC(random_state=0)\n",
    "    resultado = accuracy_score('LinearSVC', modelo, X_train, y_train)\n",
    "\n",
    "    resultados[resultado] = modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Algorithm SVC with Kernel Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def model_6(resultados):\n",
    "    from sklearn.svm import SVC\n",
    "    modelo = SVC(kernel='linear', C=0.025)\n",
    "    resultado = accuracy_score('SVC with Kernel Linear', modelo, X_train, y_train)\n",
    "\n",
    "    resultados[resultado] = modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Algorithm DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def model_7(resultados):\n",
    "    from sklearn.tree import DecisionTreeClassifier\n",
    "    modelo = DecisionTreeClassifier(random_state=0)\n",
    "    resultado = accuracy_score('DecisionTreeClassifier', modelo, X_train, y_train)\n",
    "\n",
    "    resultados[resultado] = modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Algorith Extra Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def model_8(resultados):\n",
    "    from sklearn.ensemble import ExtraTreesRegressor\n",
    "    modelo = ExtraTreesRegressor(n_estimators=10, random_state=0)\n",
    "    resultado = accuracy_score('ExtraTrees', modelo, X_train, y_train)\n",
    "\n",
    "    resultados[resultado] = modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Algorithm GaussianProcessClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def model_9(resultados):\n",
    "    from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "    from sklearn.gaussian_process.kernels import RBF\n",
    "    modelo = GaussianProcessClassifier(1.0 * RBF(1.0), warm_start=True)\n",
    "    resultado = accuracy_score('GaussianProcessClassifier', modelo, X_train, y_train)\n",
    "\n",
    "    resultados[resultado] = modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Algorithm MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def model_10(resultados):\n",
    "    from sklearn.neural_network import MLPClassifier\n",
    "    modelo = MLPClassifier(alpha=1)\n",
    "    resultado = accuracy_score('MLPClassifier', modelo, X_train, y_train)\n",
    "\n",
    "    resultados[resultado] = modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Algorithm KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def model_11(resultados):\n",
    "    from sklearn.neighbors import KNeighborsClassifier\n",
    "    modelo = KNeighborsClassifier(6)\n",
    "    resultado = accuracy_score('KNeighborsClassifier', modelo, X_train, y_train)\n",
    "\n",
    "    resultados[resultado] = modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Algorithm QuadraticDiscriminantAnalysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def model_12(resultados):\n",
    "    from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "    modelo = QuadraticDiscriminantAnalysis()\n",
    "    resultado = accuracy_score('QuadraticDiscriminantAnalysis', modelo, X_train, y_train)\n",
    "\n",
    "    resultados[resultado] = modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Algorithm GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def model_13(resultados):\n",
    "    from sklearn.naive_bayes import GaussianNB\n",
    "    modelo = GaussianNB()\n",
    "    resultado = accuracy_score('GaussianNB', modelo, X_train, y_train)\n",
    "\n",
    "    resultados[resultado] = modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Algorithm RBF SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def model_14(resultados):\n",
    "    from sklearn.svm import SVC\n",
    "    modelo = SVC(gamma=2, C=1)\n",
    "    resultado = accuracy_score('RBF SVM', modelo, X_train, y_train)\n",
    "\n",
    "    resultados[resultado] = modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Select the best algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taxa de acerto do OneVsRest: 83.66%\n",
      "Taxa de acerto do OneVsOne: 83.66%\n",
      "Taxa de acerto do MultinomialNB: 60.30%\n",
      "Taxa de acerto do AdaBoostClassifier: 83.53%\n",
      "Taxa de acerto do LinearSVC: 83.66%\n",
      "Taxa de acerto do SVC with Kernel Linear: 71.06%\n",
      "Taxa de acerto do DecisionTreeClassifier: 90.77%\n",
      "Taxa de acerto do ExtraTrees: 76.01%\n",
      "Taxa de acerto do MLPClassifier: 83.04%\n",
      "Taxa de acerto do KNeighborsClassifier: 82.92%\n",
      "Taxa de acerto do QuadraticDiscriminantAnalysis: 81.41%\n",
      "Taxa de acerto do GaussianNB: 74.06%\n",
      "Taxa de acerto do RBF SVM: 84.16%\n",
      "Taxa de acerto base: 51.74%\n",
      "\n",
      "Vencedor:\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=0, splitter='best')\n",
      "\n",
      "Taxa de acerto do algoritmo vencedor entre os algoritmos no mundo real : 94.03% \n",
      "Total de elementos : 1002\n"
     ]
    }
   ],
   "source": [
    "# Storage result of all algorithm and select the best\n",
    "resultados = {}\n",
    "\n",
    "# Create model 1\n",
    "model_1(resultados)\n",
    "# Create model 2\n",
    "model_2(resultados)\n",
    "# Create model 3\n",
    "model_3(resultados)\n",
    "# Create model 4\n",
    "model_4(resultados)\n",
    "# Create model 5\n",
    "model_5(resultados)\n",
    "# Create model 6\n",
    "model_6(resultados)\n",
    "# Create model 7\n",
    "model_7(resultados)\n",
    "# Create model 8\n",
    "model_8(resultados)\n",
    "# Create model 9\n",
    "# model_9(resultados)\n",
    "# Create model 10\n",
    "model_10(resultados)\n",
    "# Create model 11\n",
    "model_11(resultados)\n",
    "# Create model 12\n",
    "model_12(resultados)\n",
    "# Create model 13\n",
    "model_13(resultados)\n",
    "# Create model 14\n",
    "model_14(resultados)\n",
    "\n",
    "\n",
    "performance_metric(resultados, X_train, X_test, y_train, y_test);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Predicting who is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1: 148, 2: 53})\n",
      "Thiago eh vc?\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from collections import Counter\n",
    "modelo = DecisionTreeClassifier(random_state=0)\n",
    "\n",
    "X_who_is, Y_who_is, df = get_who_is()\n",
    "\n",
    "#X_who_is = df[['blink_left', 'blink_right', 'smile_or_not']]\n",
    "\n",
    "#print X_who_is\n",
    "\n",
    "modelo.fit(X, Y)\n",
    "\n",
    "predict = modelo.predict(X_who_is)\n",
    "\n",
    "result = Counter(predict)\n",
    "\n",
    "who_is = result.most_common()[0][0]\n",
    "\n",
    "print result\n",
    "\n",
    "if who_is == 1:\n",
    "    msg = \"Thiago eh vc?\"\n",
    "elif who_is == 2:\n",
    "    msg = \"Alessandro eh vc?\"\n",
    "elif who_is == 3:\n",
    "    msg = \"Ed eh vc?\"\n",
    "    \n",
    "print msg"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
